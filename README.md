
# Fine-Tuning de BETO para DetecciÃ³n de Fraude en Mensajes de Texto (Spam vs Ham)

## ğŸ“š DescripciÃ³n del Proyecto
Este proyecto realiza el **fine-tuning del modelo BETO (BERT en EspaÃ±ol)** para la tarea de **detecciÃ³n de mensajes fraudulentos (spam)** en espaÃ±ol. Utilizando un dataset de **Hugging Face** y ampliÃ¡ndolo en un **40%** con datos sintÃ©ticos, se busca mejorar la capacidad del modelo para distinguir entre mensajes **legÃ­timos (ham)** y **fraudulentos (spam)**.

El modelo final detecta con **un recall del 81% los mensajes spam**, priorizando la identificaciÃ³n de fraudes en diferentes tipos de mensajes de texto.

---

## ğŸ“¦ Dataset Utilizado
El dataset base proviene de Hugging Face y estÃ¡ disponible en el siguiente enlace:

ğŸ”— [**Dataset: spam_ham_spanish**](https://huggingface.co/datasets/softecapps/spam_ham_spanish/tree/main)

Este dataset contiene mensajes etiquetados como **ham** o **spam** en espaÃ±ol. Se ampliÃ³ en un **40%** con mensajes generados sintÃ©ticamente para mejorar el rendimiento del modelo.

---

## âš™ï¸ Arquitectura del Modelo
El modelo utilizado es **BETO**:

- **Modelo base:** `dccuchile/bert-base-spanish-wwm-uncased`
- **Tokenizador:** BertTokenizer
- **Framework:** Hugging Face Transformers

El fine-tuning se realizÃ³ utilizando **PyTorch** y el **Hugging Face Trainer API**.

---

## ğŸ§ª Resultados Clave
| MÃ©trica       | ham      | spam     | Total  |
|---------------|----------|----------|--------|
| **Precision** | 0.71     | 0.65     | 0.68   |
| **Recall**    | 0.53     | 0.81     | 0.68   |
| **F1-Score**  | 0.61     | 0.72     | 0.67   |

- **Recall para la clase spam:** 81%  
   Esto significa que el modelo detecta **la mayorÃ­a de los mensajes fraudulentos**, lo cual es esencial en tareas de detecciÃ³n de fraude.

- **PrecisiÃ³n general:** 68%  
   Se buscarÃ¡ mejorar esta mÃ©trica en iteraciones futuras.

---

## ğŸš€ CÃ³mo Ejecutar el Proyecto

1. Clona este repositorio:

```bash
git clone git@github.com:jbasurtod/nlp_fraud_detection.git
```

2. Instala las dependencias necesarias:

```bash
pip install torch transformers datasets scikit-learn
```

3. Descarga los datasets:

- `train.csv`
- `test.csv`

4. Ejecuta el entrenamiento del modelo:

```python
from transformers import Trainer

# CÃ³digo de entrenamiento
trainer.train()
```

---

## ğŸ“ˆ PrÃ³ximos Pasos
- Aumentar la precisiÃ³n general del modelo.
- Probar con tÃ©cnicas de **data augmentation** para mensajes legÃ­timos (ham).
- Ajustar los hiperparÃ¡metros para mejorar el balance entre precisiÃ³n y recall.

---

## ğŸ–‹ï¸ Autor
Proyecto realizado por **Juan Carlos Basurto**.  
Si tienes alguna pregunta o sugerencia, Â¡no dudes en contactarme!
